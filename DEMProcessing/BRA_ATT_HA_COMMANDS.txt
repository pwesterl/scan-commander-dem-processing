## SQL
# Connect
  docker exec -it geoint-db psql -U geouser -d geoint

## Inference Table
SELECT COUNT(DISTINCT source_path) AS total_processed FROM inference_status WHERE status in ('processed');
SELECT COUNT(DISTINCT (source_path, model_name)) AS total_processed FROM inference_status WHERE status in ('processed');
SELECT COUNT(*) AS total_processed FROM inference_status WHERE status in ('processed','inferencing'); \watch 5
SELECT * FROM inference_status WHERE status in ('inferencing') ORDER BY last_updated DESC LIMIT 10; \watch 5

# Kolla efter duppar:
'''
    SELECT source_path, model_name, COUNT(*) AS count
    FROM inference_status
    GROUP BY source_path, model_name
    HAVING COUNT(*) > 1;
'''

# Byt status:
'''
UPDATE inference_status
SET status = 'unprocessed',
    comment = '',
    last_updated = CURRENT_TIMESTAMP
WHERE source_path LIKE '%AW_bearbetning_2025%';
'''

'''
UPDATE inference_status
SET status = 'unprocessed'
WHERE source_path IN (
    '/app/data/AW_bearbetning_2025/Areal2908/2_dtm/dtm.tif',
    '/app/data/AW_bearbetning_2025/Areal159/2_dtm/dtm.tif',
    '/app/data/AW_bearbetning_2025/Areal2566/2_dtm/dtm.tif'
);
'''


## Preprocess Table

'''

UPDATE preprocess_status
SET status = 'unprocessed'
WHERE source_path IN (
    '/app/data/AW_bearbetning_2025/Areal2908/2_dtm/dtm.tif',
    '/app/data/AW_bearbetning_2025/Areal159/2_dtm/dtm.tif',
    '/app/data/AW_bearbetning_2025/Areal2566/2_dtm/dtm.tif'
);


'''

SELECT DISTINCT source_path FROM preprocess_status WHERE status = 
'preprocessing';
SELECT * FROM preprocess_status WHERE status = 'preprocessing' ORDER BY last_updated DESC LIMIT 100; \watch 5
SELECT COUNT(DISTINCT source_path) as processing FROM preprocess_status WHERE status = 'preprocessing';

## DB, bash
docker exec -it geoint-watcher python3 -c "from db_utils import PreprocessRepository; PreprocessRepository().create_database()"
docker exec -it geoint-watcher python3 -c "from db_utils import InferenceRepository; InferenceRepository().create_database()"
docker exec -it geoint-watcher python3 -c "from db_utils import PreprocessRepository; from pathlib import Path; PreprocessRepository(Path('/app/data/AW_bearbetning_2025')).insert_images_from_directory()" 

OBS DELETE **** docker volume rm demprocessing_db_data ********

Rabbit:
docker exec -it geoint-rabbitmq rabbitmqctl list_consumers
docker exec -it geoint-rabbitmq rabbitmqctl list_queues
docker exec -it geoint-rabbitmq rabbitmqctl list_queues name messages_ready messages_unacknowledged
docker exec -it geoint-rabbitmq rabbitmqctl list_queues
docker exec -it geoint-rabbitmq rabbitmqctl purge_queue inference
docker exec -it geoint-rabbitmq rabbitmqctl purge_queue preprocess

nvidia-for-docker:
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add -
distribution=$(. /etc/os-release; echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/liqbnvidia-container.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list


sudo apt-get install -y nvidia-container-toolkit

VALIDERA:
docker exec -it demprocessing_inference_worker python3 verify_preprocess_inference.py
docker exec -it demprocessing_preprocess_worker_1 python3 missing.py
docker exec -it demprocessing_preprocess_worker_1 python3 find_all_dtms.py
docker exec -it demprocessing_preprocess_worker_1 python3 requeue_missing_jobs.py


Testa GDAL 
python -c "import osgeo; import gdal; print(osgeo.__file__); print(gdal.VersionInfo())"
python -c "from osgeo import gdal_array"
docker run --rm -it demprocessing_inference_worker python -c "from osgeo import gdal_array; print('GDAL array OK:', hasattr(gdal_array, 'Dataset'))"

